{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM for PsP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Dense, LSTM, concatenate, Convolution2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import TimeDistributed, Dropout\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, precision_recall_curve, average_precision_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import scipy.io as spio\n",
    "from scipy import interp\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "# import dicom # install pydicom instead install dicom\n",
    "import pydicom\n",
    "\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "\n",
    "### For tuning for stochastic model and s\n",
    "# seed=random.randint(0, 2**31 - 1)\n",
    "### For reproductivity in 10-fold\n",
    "# seed= 205486557\n",
    "### For Benchmark and confirming for negative control with scrambling\n",
    "seed=7777\n",
    "### Scramble inputs for negative?\n",
    "scrambleFornegative = False\n",
    "\n",
    "\n",
    "#################\n",
    "print(seed)\n",
    "tf.random.set_seed(seed) # tf.set_random_seed(seed) # updated for TF2.2\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "### The number of input images\n",
    "timesteps = 5\n",
    "\n",
    "### FOV and pixel size\n",
    "FOV_row = 230\n",
    "FOV_col = 230\n",
    "frame_row = 256\n",
    "frame_col = 256\n",
    "channels = 1\n",
    "\n",
    "### The number of clinical features\n",
    "nb_clinic = 0\n",
    "\n",
    "### The number of class: PsPD versus PD\n",
    "nb_class = 1\n",
    "\n",
    "##################\n",
    "def clinic_model():\n",
    "    clinic = Sequential()\n",
    "    clinic.add(Flatten(input_shape=[nb_clinic, 1]))\n",
    "    clinic.add(Dense(4, activation='relu'))\n",
    "    clinic.add(Dense(4, activation='relu'))\n",
    "\n",
    "    return clinic\n",
    "\n",
    "def mri_model():\n",
    "    mri1 = Sequential()\n",
    "    mri1.add(TimeDistributed(BatchNormalization(), input_shape=[None, frame_row, frame_col, channels]))\n",
    "    mri1.add(TimeDistributed(Convolution2D(64, (2, 2), padding='same', activation='relu')))\n",
    "    mri1.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    mri1.add(TimeDistributed(BatchNormalization()))\n",
    "    mri1.add(TimeDistributed(Convolution2D(128, (2, 2), padding='same', activation='relu')))\n",
    "    mri1.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    mri1.add(TimeDistributed(BatchNormalization()))\n",
    "    mri1.add(TimeDistributed(Convolution2D(256, (2, 2), padding='same', activation='relu')))\n",
    "    mri1.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    mri1.add(TimeDistributed(Flatten()))\n",
    "    mri1.add(LSTM(24, activation='sigmoid'))\n",
    "\n",
    "    mri1.add((Dense(32, activation='relu')))\n",
    "    mri1.add((Dense(32, activation='relu')))\n",
    "\n",
    "    return mri1\n",
    "\n",
    "def mri_model (ncell):\n",
    "    mri1 = Sequential()\n",
    "    mri1.add(TimeDistributed(BatchNormalization(), input_shape=[None, frame_row, frame_col, channels]))\n",
    "    mri1.add(TimeDistributed(Convolution2D(64, (2, 2), padding='same', activation='relu')))\n",
    "    mri1.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    mri1.add(TimeDistributed(BatchNormalization()))\n",
    "    mri1.add(TimeDistributed(Convolution2D(128, (2, 2), padding='same', activation='relu')))\n",
    "    mri1.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "  \n",
    "    mri1.add(TimeDistributed(BatchNormalization()))\n",
    "    mri1.add(TimeDistributed(Convolution2D(256, (2, 2), padding='same', activation='relu')))\n",
    "    mri1.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    mri1.add(TimeDistributed(Flatten()))\n",
    "    mri1.add(LSTM(ncell, activation='sigmoid'))\n",
    "\n",
    "    mri1.add(Dense(32, activation='relu'))\n",
    "    mri1.add(Dense(32, activation='relu'))\n",
    "\n",
    "    return mri1\n",
    "\n",
    "\n",
    "\n",
    "def makemodel (ncell):\n",
    "    decoder = Sequential()\n",
    "    # decoder.add(Merge([mri_model(ncell), clinic_model()], mode='concat'))\n",
    "    decoder.add(concatenate([mri_model(ncell), clinic_model()], mode='concat'))\n",
    "    decoder.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    decoder.compile(loss='binary_crossentropy',\n",
    "                     optimizer='sgd',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return decoder\n",
    "\n",
    "def makemodel_lr (lr):\n",
    "    decoder = Sequential()\n",
    "    # decoder.add(Merge([mri_model(24), clinic_model()], mode='concat'))\n",
    "    decoder.add(concatenate([mri_model(24), clinic_model()], mode='concat'))\n",
    "    decoder.add(Dense(1, activation='sigmoid'))\n",
    "    decoder.compile(loss='binary_crossentropy',\n",
    "                     optimizer=optimizers.SGD(lr=lr),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def makemodel_wo_clinic (ncell):\n",
    "    decoder=mri_model(ncell)\n",
    "    decoder.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    decoder.compile(loss='binary_crossentropy',\n",
    "                     optimizer='sgd',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return decoder\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15+2 paths\n",
    "def run_train():\n",
    "\n",
    "    TRAIN_FOLDER = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/train'\n",
    "    x_clinic, y = load_csv(TRAIN_FOLDER)\n",
    "    # x_mri1 = load_dicom(TRAIN_FOLDER, test=False) #\n",
    "    # x_mri1=load_npz('Training/input_data_train.npz')\n",
    "    pathFile = TRAIN_FOLDER + '/train.mat'\n",
    "    x_mri1 = load_train_mat(pathFile)\n",
    "\n",
    "    ######## Parameter Tuning ###########\n",
    "    # determine_epoch(x_mri1, x_clinic, y)\n",
    "    determine_batch(x_mri1, x_clinic, y)\n",
    "    # determine_ncell(x_mri1, x_clinic, y)\n",
    "    # determine_lr (x_mri1, x_clinic, y)\n",
    "\n",
    "    ##########################################################################\n",
    "    ## 10-fold internal validation with 1 iteration in the trainingining set  #\n",
    "    ##########################################################################\n",
    "\n",
    "    scores_roc = DataFrame()\n",
    "    meanROC = list()\n",
    "\n",
    "    scores_precision = DataFrame()\n",
    "    meanPre = list()\n",
    "\n",
    "\n",
    "    if scrambleFornegative==True:\n",
    "        x_clinic=shuffle(x_clinic,random_state=seed)\n",
    "        x_mri1=shuffle(x_mri1, random_state=seed)\n",
    "\n",
    "\n",
    "    k = 3\n",
    "    iter = 3\n",
    "\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=k, shuffle=False, random_state=seed)\n",
    "\n",
    "    for i in range(iter):\n",
    "        aucs_roc, aucs_precall= cal_auc(cv, x_clinic, x_mri1, y)\n",
    "        scores_roc[str(i)] = aucs_roc\n",
    "        meanROC.append(np.mean(aucs_roc))\n",
    "\n",
    "        scores_precision[str(i)] = aucs_precall\n",
    "        meanPre.append(np.mean(aucs_precall))\n",
    "\n",
    "\n",
    "    if i>1:\n",
    "\n",
    "        print(scores_roc.describe())\n",
    "        scores_roc.boxplot()\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        print(scores_precision.describe())\n",
    "        scores_precision.boxplot()\n",
    "        plt.show()\n",
    "\n",
    "        # confidence intervals\n",
    "        alpha = 0.95\n",
    "        p = ((1.0 - alpha) / 2.0) * 100\n",
    "        lower = max(0.0, np.percentile(meanROC, p))\n",
    "        p = (alpha + ((1.0 - alpha) / 2.0)) * 100\n",
    "        upper = min(1.0, np.percentile(meanROC, p))\n",
    "        print('AUC: Grand Mean = %.1f, %.1f confidence interval %.1f%% and %.1f%%' % (np.mean(meanROC), alpha * 100, lower * 100, upper * 100))\n",
    "\n",
    "        p = ((1.0 - alpha) / 2.0) * 100\n",
    "        lower = max(0.0, np.percentile(meanPre, p))\n",
    "        p = (alpha + ((1.0 - alpha) / 2.0)) * 100\n",
    "        upper = min(1.0, np.percentile(meanPre, p))\n",
    "        print('AUPRC: Grand Mean = %.1f, %.1f confidence interval %.1f%% and %.1f%%' % (np.mean(meanPre), alpha * 100, lower * 100, upper * 100))\n",
    "\n",
    "        scores_roc.to_csv('result_roc.csv')\n",
    "        (scores_roc.describe()).to_csv('result_sum_roc.csv')\n",
    "\n",
    "        scores_precision.to_csv('result_pre.csv')\n",
    "        (scores_precision.describe()).to_csv('result_sum_pre.csv')\n",
    "\n",
    "\n",
    "\n",
    "def finalize_model():\n",
    "\n",
    "    TRAIN_FOLDER = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/train' \n",
    "    x_clinic, y = load_csv(TRAIN_FOLDER)\n",
    "    # x_mri1 = load_dicom(TRAIN_FOLDER, test=False)\n",
    "    # x_mri1=load_npz('Training/input_data_train.npz')\n",
    "    pathFile = TRAIN_FOLDER + '/train.mat'\n",
    "    x_mri1 = load_train_mat(pathFile)\n",
    "\n",
    "    ## To check out negative control\n",
    "    if scrambleFornegative==True:\n",
    "        x_clinic=shuffle(x_clinic,random_state=seed)\n",
    "        x_mri1=shuffle(x_mri1, random_state=seed)\n",
    "\n",
    "\n",
    "    NCELL=24\n",
    "    EPOCH=35\n",
    "    BATCH=8\n",
    "\n",
    "    decoder=makemodel(NCELL)\n",
    "\n",
    "    architecture = decoder.to_json()\n",
    "    with open('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/Structure.json', 'wt') as json_file:\n",
    "        json_file.write(architecture)\n",
    "\n",
    "    decoder.fit([x_mri1, x_clinic], y, batch_size=BATCH, epochs=EPOCH, shuffle=False)\n",
    "    decoder.save_weights('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/final.hdf5')\n",
    "\n",
    "def finalize_model_wo_clinic():\n",
    "    TRAIN_FOLDER = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/train'\n",
    "    x_clinic, y = load_csv(TRAIN_FOLDER)\n",
    "    # x_mri1 = load_dicom(TRAIN_FOLDER, test=False)\n",
    "    # x_mri1=load_npz('Training/input_data_train.npz')\n",
    "    pathFile = TRAIN_FOLDER + '/train.mat'\n",
    "    x_mri1 = load_train_mat(pathFile)\n",
    "    \n",
    "    NCELL=24\n",
    "    EPOCH=1000\n",
    "    BATCH=8\n",
    "\n",
    "    TEST_FOLDER = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test'\n",
    "    x_clinic, y_test = load_csv(TEST_FOLDER)\n",
    "    # x_mri1 = load_dicom(TEST_FOLDER)\n",
    "    # x_mri1 = load_npz('Testing/input_data_test.npz')\n",
    "    pathTestFile = TEST_FOLDER + '/test.mat'\n",
    "    x_test = load_test_mat(pathTestFile)\n",
    "    \n",
    "    decoder=makemodel_wo_clinic((NCELL))\n",
    "\n",
    "    architecture = decoder.to_json()\n",
    "    with open('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/Structure_wo.json', 'w') as json_file:\n",
    "        json_file.write(architecture)\n",
    "    filepath='/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/best_wo.hdf5'\n",
    "    callbacks = [ModelCheckpoint(filepath, verbose=0, save_best_only=True, save_weights_only=True)]\n",
    "    h = decoder.fit(x_mri1, y, batch_size=BATCH, epochs=EPOCH, shuffle=False, validation_data=(x_test,y_test), verbose=1)\n",
    "    decoder.save_weights('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/final_wo.hdf5')\n",
    "\n",
    "    \"\"\"\n",
    "    # Trained the model\n",
    "    # Compile the model\n",
    "    decoder.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                  metrics=['acc'])\n",
    "    # Train the model\n",
    "    history = decoder.fit_generator(\n",
    "          train_generator,\n",
    "          steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "          epochs=20,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "          verbose=1)\n",
    "    \"\"\"\n",
    "    return h\n",
    "\n",
    "def run_test():\n",
    "\n",
    "    TEST_FOLDER = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test'\n",
    "    x_clinic, y = load_csv(TEST_FOLDER)\n",
    "    # x_mri1 = load_dicom(TEST_FOLDER)\n",
    "    # x_mri1 = load_npz('Testing/input_data_test.npz')\n",
    "    pathFile = TEST_FOLDER + '/test.mat'\n",
    "    x_mri1 = load_test_mat(pathFile)\n",
    "    \n",
    "    json_file = open('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/Structure.json', 'rt')\n",
    "    architecture = json_file.read()\n",
    "    json_file.close()\n",
    "    models = model_from_json(architecture)\n",
    "\n",
    "    models.load_weights('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/final.hdf5')\n",
    "    show_auc(models, x_mri1, x_clinic, y)\n",
    "\n",
    "def run_test_wo_clinic():\n",
    "\n",
    "    TEST_FOLDER = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test'\n",
    "    x_clinic, y = load_csv(TEST_FOLDER)\n",
    "    # x_mri1 = load_dicom(TEST_FOLDER)\n",
    "    # x_mri1 = load_npz('Testing/input_data_test.npz')\n",
    "    pathFile = TEST_FOLDER + '/test.mat'\n",
    "    x_mri1 = load_test_mat(pathFile)\n",
    "\n",
    "    json_file = open('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/Structure_wo.json', 'rt')\n",
    "    architecture = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    models = model_from_json(architecture)\n",
    "\n",
    "    models.load_weights('/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test/model/final_wo.hdf5')\n",
    "    show_auc_wo_clinic(models, x_mri1, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_auc(cv, x_clinic, x_mri1, y):\n",
    "    tprs = []\n",
    "    aucs_roc = []\n",
    "    aucs_precall = []\n",
    "    ytests =[]\n",
    "    probas = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    i = 0\n",
    "\n",
    "    for train, test in cv.split(x_clinic, y):\n",
    "        classifier = makemodel(24)\n",
    "        classifier.fit([x_mri1[train], x_clinic[train]], y[train], batch_size=8, epochs=25, verbose=2)\n",
    "\n",
    "        probas_ = classifier.predict([x_mri1[test], x_clinic[test]], batch_size=8)\n",
    "\n",
    "        # Compute ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs_roc.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC of fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        # Compute precision-recall curve\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y[test], probas_)\n",
    "        average_precision[i] = average_precision_score(y[test], probas_)\n",
    "        ytests.append(y[test])\n",
    "        probas.append(probas_)\n",
    "\n",
    "        i += 1\n",
    "        K.clear_session()    \n",
    "        \n",
    "        \n",
    "    ################################################\n",
    "    ###########   Plotting ROC curve  ##############\n",
    "    ################################################\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Luck', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs_roc)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # plt.savefig('Mean ROC (AUC = %0.2f -- %0.2f).pdf' % (mean_auc, std_auc), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    ################################################\n",
    "    ##### Plotting Precision-Recall curve ##########\n",
    "    ################################################\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(np.concatenate(ytests),np.concatenate(probas))\n",
    "    average_precision[\"micro\"] = average_precision_score(y[test], probas_, average=\"micro\")\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "             label='micro-average Precision-recall curve (AUPRC = {0:0.2f})'\n",
    "                   ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "    for j in range(i):\n",
    "        plt.plot(recall[j], precision[j],\n",
    "                 label='Precision-recall curve of fold {0} (AUPRC = {1:0.2f})'\n",
    "                       ''.format(j, average_precision[j]))\n",
    "        aucs_precall.append(average_precision[j])\n",
    "\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    currenttime = datetime.now().strftime(\"%H%M%S\")\n",
    "    # plt.savefig('Precision-Recall Curve (AUPRC = %0.2f)_' % (average_precision[\"micro\"]) + currenttime +'.pdf' , format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    return aucs_roc, aucs_precall\n",
    "\n",
    "def show_auc(classifier, x_mri1, x_clinic, y):\n",
    "\n",
    "    probas_ = classifier.predict([x_mri1, x_clinic], batch_size=8)\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, threshold = roc_curve(y, probas_)\n",
    "    tpr[0]=0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC Curve (AUC = %0.2f)' % (roc_auc), alpha=1, color='b')\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y, probas_)\n",
    "    average_precision = average_precision_score(y, probas_)\n",
    "\n",
    "    ################################################\n",
    "    ###########   Plotting ROC curve  ##############\n",
    "    ################################################\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, alpha=0.2, color='r',label='Luck')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # plt.savefig('Final ROC (AUC = %0.2f).pdf' % (roc_auc), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    ################################################\n",
    "    ##### Plotting Precision-Recall curve ##########\n",
    "    ################################################\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "\n",
    "    plt.plot(recall, precision,label='Precision-Recall Curve (AUPRC = {0:0.2f})'''.format(average_precision))\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.savefig('Final Precision-Recall (AUPRC = %0.2f).pdf' % (average_precision), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    ##### Confusion Matrix #########################\n",
    "    ################################################\n",
    "\n",
    "\n",
    "    # The optimal cut off would be where tpr is high and fpr is low\n",
    "    # tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "\n",
    "    i = np.arange(len(tpr))  # index for df\n",
    "    roc = pd.DataFrame(\n",
    "        {'fpr': pd.Series(fpr, index=i), 'tpr': pd.Series(tpr, index=i), '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "         'tf': pd.Series(tpr - (1 - fpr), index=i), 'threshold': pd.Series(threshold, index=i)})\n",
    "    roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "\n",
    "    #### Confusion Matrix\n",
    "    roc_t = roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "    optimal_cutoff = list(roc_t['threshold'])\n",
    "    print (optimal_cutoff)\n",
    "    report = classification_report(y, probas_ >= optimal_cutoff)\n",
    "    print (report)\n",
    "\n",
    "    cm = confusion_matrix(y, probas_ >= optimal_cutoff)\n",
    "    print(cm)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "\n",
    "    plt.matshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.show()\n",
    "\n",
    "def show_auc_wo_clinic (classifier, x_mri1, y):\n",
    "\n",
    "\n",
    "    probas_ = classifier.predict([x_mri1], batch_size=8)\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, threshold = roc_curve(y, probas_)\n",
    "    tpr[0]=0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC Curve (AUC = %0.2f)' % (roc_auc), alpha=1, color='orange')\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y, probas_)\n",
    "    average_precision = average_precision_score(y, probas_)\n",
    "\n",
    "    ################################################\n",
    "    ###########   Plotting ROC curve  ##############\n",
    "    ################################################\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, alpha=0.2, color='r',label='Random')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    #plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.gca().set_aspect(0.75, adjustable='box')\n",
    "    \n",
    "    # plt.savefig('Final ROC wo clinic (AUC = %0.2f).pdf' % (roc_auc), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    ################################################\n",
    "    ##### Plotting Precision-Recall curve ##########\n",
    "    ################################################\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "\n",
    "    plt.plot(recall, precision,label='Precision-Recall Curve (AUC = {0:0.2f})'''.format(average_precision), color='orange')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.savefig('Final Precision-Recall wo clinic(AUC = %0.2f).pdf' % (average_precision), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    ##### Confusion Matrix #########################\n",
    "    ################################################\n",
    "\n",
    "\n",
    "    # The optimal cut off would be where tpr is high and fpr is low\n",
    "    # tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "\n",
    "    i = np.arange(len(tpr))  # index for df\n",
    "    roc = pd.DataFrame(\n",
    "        {'fpr': pd.Series(fpr, index=i), 'tpr': pd.Series(tpr, index=i), '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "         'tf': pd.Series(tpr - (1 - fpr), index=i), 'threshold': pd.Series(threshold, index=i)})\n",
    "    roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "\n",
    "    #### Confusion Matrix\n",
    "    roc_t = roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "    optimal_cutoff = list(roc_t['threshold'])\n",
    "    print (optimal_cutoff)\n",
    "    report = classification_report(y, probas_ >= optimal_cutoff)\n",
    "    print (report)\n",
    "\n",
    "    cm = confusion_matrix(y, probas_ >= optimal_cutoff)\n",
    "    print(cm)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "\n",
    "    plt.matshow(cm, cmap=plt.cm.Oranges)\n",
    "    plt.colorbar()\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_history (history):\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model train vs validation loss')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_csv(path):\n",
    "    pathfile = path+'/y.csv'\n",
    "    dataframe = pd.read_csv(pathfile)\n",
    "    dataset = dataframe.values\n",
    "\n",
    "\n",
    "    X = np.array (dataset[:, 0:nb_clinic+1].astype(float))\n",
    "    Y = np.array(dataset[:, nb_clinic+1])\n",
    "\n",
    "    scaler = MinMaxScaler (feature_range=(0,1))\n",
    "    scalerX = scaler.fit(X)\n",
    "    normalizedX = scalerX.transform(X)\n",
    "\n",
    "    X = normalizedX.reshape(normalizedX.shape[0], normalizedX.shape[1], 1)\n",
    "    return X,Y\n",
    "\n",
    "def load_dicom(path, test=False):\n",
    "\n",
    "\n",
    "    mark = ['0000', '0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008']\n",
    "    n = len(os.listdir(path)) - 1\n",
    "    j = 0\n",
    "\n",
    "    stack = np.zeros((timesteps, frame_row, frame_col))\n",
    "    data = np.zeros((n, timesteps, frame_row, frame_col))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        for ptnum in os.listdir(path):\n",
    "            if ptnum == 'sample.csv':\n",
    "                continue\n",
    "            else:\n",
    "                for i in mark:\n",
    "                    # dcm_struct=dicom.read_file(path + '/' + ptnum + '/' + ptnum + '_' + i + '.dcm')\n",
    "                    dcm_struct=pydicom.read_file(path + '/' + ptnum + '/' + ptnum + '_' + i + '.dcm')\n",
    "                    pixel_size=dcm_struct.PixelSpacing[0]\n",
    "                    img = dcm_struct.pixel_array\n",
    "                    plt.imshow(img, cmap=plt.cm.gray)\n",
    "                    img = img.reshape(img.shape[0],img.shape[1],1)\n",
    "                    img = img.astype(int)\n",
    "                    print(i,j)\n",
    "                    img = tf.image.resize_image_with_crop_or_pad(img, int(round(FOV_row/pixel_size)), int(round(FOV_col/pixel_size)))\n",
    "                    img = tf.image.resize_images(img, size=[frame_row, frame_col], method=tf.image.ResizeMethod.BICUBIC)\n",
    "                    img = tf.image.per_image_standardization(img)\n",
    "\n",
    "                    img_array = sess.run(img)\n",
    "                    img_array = img_array.reshape(img.shape[0], img.shape[1])\n",
    "                    plt.imshow(img_array, cmap=plt.cm.gray)\n",
    "                    stack[int(i), :, :] = img_array\n",
    "\n",
    "            data [j,:,:,:] = stack\n",
    "            j = j+1\n",
    "\n",
    "\n",
    "    data = data.reshape(data.shape[0], data.shape[1], data.shape[2], data.shape[3], channels)\n",
    "\n",
    "    if test==True:\n",
    "        np.savez_compressed('input_data_test.npz', data)\n",
    "    else:\n",
    "        np.savez_compressed('input_data_train.npz', data)\n",
    "\n",
    "    # show_slice(data[0][4])\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_npz(file):\n",
    "    data=np.load(file)\n",
    "    data=data['arr_0']\n",
    "    return data\n",
    "\n",
    "def load_test_mat(file):\n",
    "    fileDir = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/test'\n",
    "    fileName = fileDir + '/test.mat'\n",
    "    data = spio.loadmat(fileName)['IMG']\n",
    "    data = np.ascontiguousarray(data.T)\n",
    "    data = np.swapaxes(data,2,4)\n",
    "    # data = data[:,:,:,:,np.newaxis]\n",
    "    return data\n",
    "\n",
    "def load_train_mat(file):\n",
    "    fileDir = '/data/jslee/PsP/PsPData/MatData_lstm/PsP43/Modality_7/CV1/train'\n",
    "    fileName = fileDir + '/train.mat'\n",
    "    data = spio.loadmat(fileName)['IMG']\n",
    "    data = np.ascontiguousarray(data.T)\n",
    "    data = np.swapaxes(data,2,4)\n",
    "    # data = data[:,:,:,:,np.newaxis]\n",
    "    return data\n",
    "\n",
    "def show_slice(arr, value_range=None):\n",
    "    if len(list(arr.shape)) > 2:\n",
    "        arr2 = arr.copy()\n",
    "        arr2 = np.reshape(arr, (arr.shape[0], arr.shape[1]))\n",
    "    else:\n",
    "        arr2 = arr\n",
    "\n",
    "    dpi = 80\n",
    "    margin = 0.05  # (5% of the width/height of the figure...)\n",
    "    xpixels, ypixels = arr2.shape[0], arr2.shape[1]\n",
    "\n",
    "    figsize = (1 + margin) * ypixels / dpi, (1 + margin) * xpixels / dpi\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    # Make the axis the right size...\n",
    "    ax = fig.add_axes([margin, margin, 1 - 2 * margin, 1 - 2 * margin])\n",
    "\n",
    "\n",
    "    if value_range is None:\n",
    "        plt.imshow(arr2, cmap=plt.cm.gray)\n",
    "    else:\n",
    "         plt.imshow(arr2, vmin=value_range[0], vmax=1, cmap=plt.cm.gray, interpolation='none')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def random_forest():\n",
    "\n",
    "    TRAIN_FOLDER = 'C:/Users/JBS/Desktop/PsPDtrain_1mm(SNUH)'\n",
    "    TEST_FOLDER = 'C:/Users/JBS/Desktop/PsPDtest_1mm(SNUBH)'\n",
    "    testX_clinic, testY = load_csv(TEST_FOLDER)\n",
    "    trainX_clinic, trainY = load_csv(TRAIN_FOLDER)\n",
    "\n",
    "    x1=trainX_clinic.shape[0]\n",
    "    x2=trainX_clinic.shape[1]\n",
    "    trainX_clinic= trainX_clinic.reshape(x1,x2)\n",
    "\n",
    "    x1=testX_clinic.shape[0]\n",
    "    x2=testX_clinic.shape[1]\n",
    "    testX_clinic= testX_clinic.reshape(x1,x2)\n",
    "\n",
    "\n",
    "\n",
    "#### Internal Val in the training set\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    "    rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=seed)\n",
    "    results = cross_val_score(rf, trainX_clinic, trainY, cv=cv)\n",
    "    print(results.mean())\n",
    "\n",
    "    tprs = []\n",
    "    aucs_roc = []\n",
    "    aucs_precall = []\n",
    "    ytests =[]\n",
    "    probas = []\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    i = 0\n",
    "\n",
    "    for train, test in cv.split(trainX_clinic, trainY):\n",
    "        rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=seed)\n",
    "        rf.fit(trainX_clinic[train], trainY[train])\n",
    "        probas_ = rf.predict(trainX_clinic[test])\n",
    "\n",
    "        # Compute ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(trainY[test], probas_)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs_roc.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC of fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        # Compute precision-recall curve\n",
    "        precision[i], recall[i], _ = precision_recall_curve(trainY[test], probas_)\n",
    "        average_precision[i] = average_precision_score(trainY[test], probas_)\n",
    "        ytests.append(trainY[test])\n",
    "        probas.append(probas_)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    ###########   Plotting ROC curve  ##############\n",
    "    ################################################\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Luck', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs_roc)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # plt.savefig('RF_internal_Mean ROC (AUC = %0.2f -- %0.2f).pdf' % (mean_auc, std_auc), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "#### External Val in the testing set\n",
    "    rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=seed)\n",
    "    rf.fit(trainX_clinic, trainY)\n",
    "\n",
    "    probas_ = rf.predict(testX_clinic)\n",
    "    accuracy = accuracy_score(testY, probas_)\n",
    "\n",
    "    print(f'Out-of-bag score estimate: {rf.oob_score_:.3}')\n",
    "    print(f'Mean accuracy score: {accuracy:.3}')\n",
    "\n",
    "\n",
    "   # Compute ROC curve\n",
    "    fpr, tpr, threshold = roc_curve(testY, probas_)\n",
    "    tpr[0]=0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC Curve (AUC = %0.2f)' % (roc_auc), alpha=1, color='g')\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(testY, probas_)\n",
    "    average_precision = average_precision_score(testY, probas_)\n",
    "\n",
    "    ################################################\n",
    "    ###########   Plotting ROC curve  ##############\n",
    "    ################################################\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, alpha=0.2, color='r',label='Luck')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # plt.savefig('RF_ROC (AUC = %0.2f).pdf' % (roc_auc), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    ################################################\n",
    "    ##### Plotting Precision-Recall curve ##########\n",
    "    ################################################\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "\n",
    "    plt.plot(recall, precision,label='Precision-Recall Curve (AUPRC = {0:0.2f})'''.format(average_precision), color='green')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.savefig('RF_Precision-Recall (AUPRC = %0.2f).pdf' % (average_precision), format='pdf')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    ##### Confusion Matrix #########################\n",
    "    ################################################\n",
    "\n",
    "\n",
    "    # The optimal cut off would be where tpr is high and fpr is low\n",
    "    # tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "\n",
    "    i = np.arange(len(tpr))  # index for df\n",
    "    roc = pd.DataFrame(\n",
    "        {'fpr': pd.Series(fpr, index=i), 'tpr': pd.Series(tpr, index=i), '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "         'tf': pd.Series(tpr - (1 - fpr), index=i), 'threshold': pd.Series(threshold, index=i)})\n",
    "    roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "\n",
    "    #### Confusion Matrix\n",
    "    roc_t = roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "    optimal_cutoff = list(roc_t['threshold'])\n",
    "    print (optimal_cutoff)\n",
    "    report = classification_report(testY, probas_ >= optimal_cutoff)\n",
    "    print (report)\n",
    "\n",
    "    cm = confusion_matrix(testY, probas_ >= optimal_cutoff)\n",
    "    print(cm)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "\n",
    "    plt.matshow(cm, cmap=plt.cm.Greens)\n",
    "    plt.colorbar()\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    # plt.savefig('Confusion matrix.pdf', format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "###### Model 1 ######\n",
    "     # run_train()\n",
    "     # finalize_model()\n",
    "     # run_test()\n",
    "\n",
    "###### Model 2 ######\n",
    "     h = finalize_model_wo_clinic()\n",
    "     #run_test_wo_clinic()\n",
    "\n",
    "###### Model 3 ######\n",
    "     # random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check Performance\n",
    "history = h\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_test_wo_clinic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ROC curve & Load Model ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move test/train folders to C:\\Users\\leejoons\\PROJECTS_DATA\\1-1_PsP\\PsPData\\ImageData\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model, Sequential, model_from_json\n",
    "from itertools import cycle\n",
    "import math\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "threshold = dict()\n",
    "roc_auc = dict()\n",
    "accuracy = dict()\n",
    "interval = dict()\n",
    "optimal_cutoff = dict()\n",
    "y_true = dict()\n",
    "y_pred = dict()\n",
    "probability = dict()\n",
    "\n",
    "n_classes = 3\n",
    "nb_clinic = 0\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model ---- change n_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move test folder to 'C:/Users/leejoons/PROJECTS_DATA/1-1_PsP/PsPData/MatData/test'\n",
    "n_cv = 0 # 0: cv1 k-fold cv\n",
    "\n",
    "nb_clinic = 0\n",
    "def load_csv(path):\n",
    "    pathfile = path+'/y.csv'\n",
    "    dataframe = pd.read_csv(pathfile)\n",
    "    dataset = dataframe.values\n",
    "    X = np.array (dataset[:, 0:nb_clinic+1].astype(float))\n",
    "    Y = np.array(dataset[:, nb_clinic+1])\n",
    "    scaler = MinMaxScaler (feature_range=(0,1))\n",
    "    scalerX = scaler.fit(X)\n",
    "    normalizedX = scalerX.transform(X)\n",
    "    X = normalizedX.reshape(normalizedX.shape[0], normalizedX.shape[1], 1)\n",
    "    return X,Y\n",
    "\n",
    "def load_test_mat(file):\n",
    "    fileDir = 'E:/PROJECTS/1_RAD/PsP/PsPData/MatData_lstm/PsP43/Modality_3/CV1/test'\n",
    "    fileName = fileDir + '/test.mat'\n",
    "    data = spio.loadmat(fileName)['IMG']\n",
    "    data = np.ascontiguousarray(data.T)\n",
    "    data = np.swapaxes(data,2,4)\n",
    "    # data = data[:,:,:,:,np.newaxis]\n",
    "    return data\n",
    "\n",
    "def run_test_wo_clinic():\n",
    "    TEST_FOLDER = 'E:/PROJECTS/1_RAD/PsP/PsPData/MatData_lstm/PsP43/Modality_3/CV1/test'\n",
    "    x_clinic, y = load_csv(TEST_FOLDER)\n",
    "    pathFile = TEST_FOLDER + '/test.mat'\n",
    "    x_mri1 = load_test_mat(pathFile)\n",
    "    json_file = open('E:/PROJECTS/1_RAD/PsP/PsPData/MatData_lstm/PsP43/Modality_3/CV1/test/model/Structure_wo.json', 'rt')\n",
    "    architecture = json_file.read()\n",
    "    json_file.close()\n",
    "    models = model_from_json(architecture)\n",
    "    #models.load_weights('C:/Users/leejoons/PROJECTS_DATA/1-1_PsP/PsPData/MatData/test/best_wo.hdf5')\n",
    "    models.load_weights('E:/PROJECTS/1_RAD/PsP/PsPData/MatData_lstm/PsP43/Modality_3/CV1/test/model/final_wo.hdf5')\n",
    "\n",
    "    return models, x_mri1, y\n",
    "\n",
    "models, x_mri1, y = run_test_wo_clinic()\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve\n",
    "i = n_cv # ith in k-folds 0:cv1, 1:cv2, 2:cv3 <-------------------- modify fold number \n",
    "\n",
    "prob = models.predict([x_mri1], batch_size=8)\n",
    "fpr[i], tpr[i], threshold[i] = roc_curve(y, prob)\n",
    "roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "y_true[i] = y\n",
    "probability[i] = prob\n",
    "\n",
    "print('# of var = ', len(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optimal cut off would be where tpr is high and fpr is low\n",
    "# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "# import pandas as pd\n",
    "\n",
    "k = np.arange(len(tpr[i]))  # index for df\n",
    "roc = pd.DataFrame(\n",
    "    {'fpr': pd.Series(fpr[i], index=k), 'tpr': pd.Series(tpr[i], index=k), '1-fpr': pd.Series(1 - fpr[i], index=k),\n",
    "         'tf': pd.Series(tpr[i] - (1 - fpr[i]), index=k), 'threshold': pd.Series(threshold[i], index=k)})\n",
    "\n",
    "roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "\n",
    "#### Confusion Matrix\n",
    "roc_t = roc.loc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "optimal_cutoff[i] = list(roc_t['threshold'])\n",
    "print (optimal_cutoff[i])\n",
    "# print(probas_[0:5])\n",
    "report = classification_report(y_true[i], probability[i] >= optimal_cutoff[i])\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(y_true[i], probability[i] >= optimal_cutoff[i])\n",
    "print(cm)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Something wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.squeeze(prob)\n",
    "probs[probs >= optimal_cutoff[i]] = 1\n",
    "probs[probs < optimal_cutoff[i]] = 0\n",
    "probs = probs.astype(np.int64)\n",
    "y_pred[i] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 95% C.I. for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# from sklearn.metrics import f1_score\n",
    "accuracy[i] = f1_score(y, prob >= optimal_cutoff[i], average='micro')\n",
    "interval[i] = 1.96 * math.sqrt( (accuracy[i] * (1 - accuracy[i])) / len(y))\n",
    "print('95% C.I. = {:.4f} \\u00B1 {:.4f}'.format(accuracy[i], interval[i]))\n",
    "\n",
    "a = accuracy[i] - interval[i]\n",
    "b = accuracy[i] + interval[i]\n",
    "print('95% C.I. = [{:.4f} - {:.4f}]'.format(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save y variables to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = n_cv\n",
    "import numpy as np\n",
    "np.savetxt(\"y_prob.csv\", probability[i], delimiter=\",\")\n",
    "np.savetxt(\"y_true.csv\", y_true[i], delimiter=\",\")\n",
    "print(roc_auc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inverse value\n",
    "A = tpr[i]\n",
    "B = fpr[i]\n",
    "tpr[i] = B\n",
    "fpr[i] = A\n",
    "roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "print(roc_auc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------> go to R for 95% IC for AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 95% C.I using bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# y_pred = np.array([0.21, 0.32, 0.63, 0.35, 0.92, 0.79, 0.82, 0.99, 0.04])\n",
    "# y_true = np.array([0,    1,    0,    0,    1,    1,    0,    1,    0   ])\n",
    "y_pr = y_pred[i]\n",
    "y_tr = y_true[i]\n",
    "\n",
    "print(\"Original ROC area: {:0.3f}\".format(roc_auc_score(y_tr, y_pr)))\n",
    "\n",
    "n_bootstraps = 1000\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.random_integers(0, len(y_pr) - 1, len(y_pr))\n",
    "    if len(np.unique(y_tr[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "    score = roc_auc_score(y_tr[indices], y_pr[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    # print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))\n",
    "\n",
    "plt.hist(bootstrapped_scores, bins=50)\n",
    "plt.title('Histogram of the bootstrapped ROC AUC scores')\n",
    "plt.show()\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----> Load Next Model for the Multi-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], lw=1, label='ROC Curve (AUC = %0.2f)' % (roc_auc[i]), alpha=1, color=color)\n",
    "    print('AUC_{} = {:.4f}' .format(i, roc_auc[i]))\n",
    "print('Mean AUC = {:.4f}'.format((roc_auc[0]+roc_auc[1]+roc_auc[2])/3))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, alpha=0.2, color='r',label='Luck')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# plt.savefig('Final ROC wo clinic (AUC = %0.2f).pdf' % (roc_auc), format='pdf')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array([roc_auc[0], roc_auc[1], roc_auc[2]])\n",
    "print(dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "# dataset = np.array([[1,2,3,3,4,4,2], [3,2,5,3,3,3,3], [3,4,3,5,2,2,3]])\n",
    "dataset = np.array([roc_auc[0], roc_auc[1], roc_auc[2]])\n",
    "# df = pd.DataFrame(dataset, columns=['T1', 'T1post', 'T2', 'FLAIR', 'ADC', 'T1post-T1', 'T2-FLAIR'])\n",
    "df = pd.DataFrame(dataset, columns=['CNN-LSTM 5'])\n",
    "ax = df.plot.box(grid='True', title='Boxplot for T1 post', colormap='jet')\n",
    "# ax = df.plot(lw=1,colormap='jet',marker='.',markersize=10,title='Boxplot for T1 Post')\n",
    "# set labels for both axes\n",
    "ax.set(ylabel='AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the objects:\n",
    "with open('Var_7Mod_LSTM_9var.pkl', 'wb') as f:  \n",
    "    pickle.dump([fpr, tpr, threshold, roc_auc, accuracy, interval, optimal_cutoff, y_true, probability], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Getting back the objects:\n",
    "with open('Var_5Mod_LSTM_9var.pkl', 'rb') as f:  \n",
    "    fpr, tpr, threshold, roc_auc, accuracy, interval, optimal_cutoff, y_true, probability = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_true[1])\n",
    "print(y_pred[1])\n",
    "np.savetxt(\"foo.csv\", y_pred[2], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
